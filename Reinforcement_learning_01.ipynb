{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utUn0BLctFST",
        "outputId": "a61b626d-cfeb-44d6-bde4-6cb28f14e78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action: right, State: (0, 1), Reward: -1\n",
            "Action: right, State: (0, 2), Reward: -1\n",
            "Action: right, State: (0, 3), Reward: -1\n",
            "Action: right, State: (0, 4), Reward: 10\n",
            "Total Reward: 7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the environment\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.grid = np.array([\n",
        "            ['S', ' ', ' ', ' ', 'G'],\n",
        "            [' ', 'X', ' ', 'X', ' '],\n",
        "            [' ', 'X', ' ', 'X', ' '],\n",
        "            [' ', ' ', ' ', 'X', ' '],\n",
        "            [' ', 'X', ' ', ' ', ' ']\n",
        "        ])\n",
        "        self.start = (0, 0)\n",
        "        self.goal = (0, 4)\n",
        "        self.state = self.start\n",
        "        self.actions = ['up', 'down', 'left', 'right']\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        row, col = self.state\n",
        "        if action == 'up':\n",
        "            row = max(row - 1, 0)\n",
        "        elif action == 'down':\n",
        "            row = min(row + 1, 4)\n",
        "        elif action == 'left':\n",
        "            col = max(col - 1, 0)\n",
        "        elif action == 'right':\n",
        "            col = min(col + 1, 4)\n",
        "\n",
        "        next_state = (row, col)\n",
        "\n",
        "        if self.grid[row, col] == 'X':\n",
        "            next_state = self.state  # Stay in the same place if hit an obstacle\n",
        "\n",
        "        reward = -1\n",
        "        done = False\n",
        "        if next_state == self.goal:\n",
        "            reward = 10\n",
        "            done = True\n",
        "\n",
        "        self.state = next_state\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def get_state_index(self, state):\n",
        "        return state[0] * 5 + state[1]\n",
        "\n",
        "# Define the Q-learning algorithm\n",
        "class QLearningAgent:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.env = env\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.q_table = np.zeros((25, len(env.actions)))\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(self.env.actions)\n",
        "        else:\n",
        "            state_index = self.env.get_state_index(state)\n",
        "            return self.env.actions[np.argmax(self.q_table[state_index])]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        state_index = self.env.get_state_index(state)\n",
        "        next_state_index = self.env.get_state_index(next_state)\n",
        "        action_index = self.env.actions.index(action)\n",
        "\n",
        "        best_next_action = np.argmax(self.q_table[next_state_index])\n",
        "        td_target = reward + self.gamma * self.q_table[next_state_index][best_next_action]\n",
        "        td_error = td_target - self.q_table[state_index][action_index]\n",
        "\n",
        "        self.q_table[state_index][action_index] += self.alpha * td_error\n",
        "\n",
        "# Train the agent\n",
        "env = GridWorld()\n",
        "agent = QLearningAgent(env)\n",
        "\n",
        "episodes = 1000\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward, done = env.step(action)\n",
        "        agent.learn(state, action, reward, next_state)\n",
        "        state = next_state\n",
        "\n",
        "# Test the agent\n",
        "state = env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action = agent.choose_action(state)\n",
        "    next_state, reward, done = env.step(action)\n",
        "    total_reward += reward\n",
        "    state = next_state\n",
        "\n",
        "    print(f\"Action: {action}, State: {next_state}, Reward: {reward}\")\n",
        "\n",
        "print(f\"Total Reward: {total_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VsB_LBittJf-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}